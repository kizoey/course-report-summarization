{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[KUBIG] T5 강의평가 요약.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9EkQwCS9Ywl",
        "outputId": "b67b6aed-467a-4ceb-88a3-dbc16299c267"
      },
      "source": [
        "!pip install sentencepiece==0.1.91"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece==0.1.91\n",
            "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 17.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 112 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 122 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 133 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 143 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 153 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 163 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 174 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 184 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 194 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 204 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 215 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 225 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 235 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 245 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 256 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 266 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 276 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 286 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 296 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 307 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 317 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 327 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 337 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 348 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 358 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 368 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 378 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 389 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 399 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 409 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 419 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 430 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 440 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 450 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 460 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 471 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 481 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 491 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 501 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 512 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 522 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 532 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 542 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 552 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 563 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 573 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 583 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 593 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 604 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 614 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 624 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 634 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 645 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 655 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 665 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 675 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 686 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 696 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 706 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 716 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 727 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 737 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 747 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 757 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 768 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 778 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 788 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 798 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 808 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 819 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 829 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 839 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 849 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 860 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 870 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 880 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 890 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 901 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 911 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 921 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 931 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 942 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 952 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 962 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 972 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 983 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 993 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.0 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.0 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 12.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "892bzr4pCYGU",
        "outputId": "11e614e4-7974-48e4-8337-ceb3f3c510fd"
      },
      "source": [
        "!pip install transformers -q\n",
        "!pip install wandb -q\n",
        "\n",
        "# Code for TPU packages install\n",
        "# !curl -q https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "# !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.9 MB 10.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 41.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 31.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 43.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 13.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 139 kB 52.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 32.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3EjeCTiCaoa"
      },
      "source": [
        "# Importing stock libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# WandB – Import the wandb library\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8_CBoO5CTs-",
        "outputId": "2987d35c-b67e-4ab8-e055-809a98415cd0"
      },
      "source": [
        "# Checking out the GPU we have access to. This is output is from the google colab version. \n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct 13 06:48:09 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvDEHeMr8EIG"
      },
      "source": [
        "# Setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# Preparing for TPU usage\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "# device = xm.xla_device()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtxx7k1B8FlJ",
        "outputId": "b1c0e4f6-a25b-4a63-ae13-44ac26fd0a95"
      },
      "source": [
        "# Login to wandb to log the model run and all the parameters\n",
        "!wandb login"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z45-K_jQ8tot"
      },
      "source": [
        "### 1. Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSIzR-d-_VLj",
        "outputId": "162b375b-3fcd-4b24-f02e-f9e4c6bfd7ac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wijfKLYa3Ke",
        "outputId": "8682f8f8-67a3-41c8-b8c3-a3e5b16d3056"
      },
      "source": [
        "cd /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xsQOLTm_Xfn",
        "outputId": "6206f8b1-81dc-480e-dddf-61305f9fa2d0"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Colab Notebooks'\t\t\t\t      t5_predictions.csv\n",
            " klue_info_text.xlsx\t\t\t\t     '문서요약 텍스트_unzip'\n",
            "'[데이터톤] KLUE 강의평 텍스트 데이터 khaiii.ipynb'   wandb\n",
            "'[KUBIG] KLUE 강의평 전처리.ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "kgBQF17q39mi",
        "outputId": "5727d4ea-26e8-4982-f1a1-1048ebab35d2"
      },
      "source": [
        "# Loading train/validation data\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def read_jsonl(path):\n",
        "  DATA_DIR = \"문서요약 텍스트_unzip\"\n",
        "  with open(DATA_DIR + path , 'r') as json_file:\n",
        "      json_list = list(json_file)\n",
        "\n",
        "  trains = []\n",
        "\n",
        "  for json_str in json_list:\n",
        "      line = json.loads(json_str)\n",
        "      trains.append(line)\n",
        "  df = pd.DataFrame(trains)\n",
        "  return df\n",
        "\n",
        "train_df = read_jsonl('/1.Training/신문기사_1.train.jsonl/train.jsonl')\n",
        "val_df = read_jsonl('/2.Validation/신문기사_1.vaild.jsonl/vaild.jsonl')\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>media</th>\n",
              "      <th>id</th>\n",
              "      <th>article_original</th>\n",
              "      <th>abstractive</th>\n",
              "      <th>extractive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>부산일보</td>\n",
              "      <td>360972161</td>\n",
              "      <td>[지난해 고령화와 유례가 드문 겨울 한파 등 영향으로 우리나라 사망자 수가 통계 작...</td>\n",
              "      <td>통계청이 발표한 '2018년 사망원인통계'를 보면 지난해 총 사망자 수는 관련 통계...</td>\n",
              "      <td>[4, 11, 18]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>중도일보</td>\n",
              "      <td>356659913</td>\n",
              "      <td>[서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 ...</td>\n",
              "      <td>서산시 가충순 의원과 이수의 의원이 활발한 의정활동을 펼친 감사의 표시로 한국지역신...</td>\n",
              "      <td>[1, 3, 4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>무등일보</td>\n",
              "      <td>351718460</td>\n",
              "      <td>[지난 2004년 시작해 조선대 학생들의 대표적인 행사로 자리매김한 ‘조선대 국토대...</td>\n",
              "      <td>‘조선대의 새로운 비상을 꿈꾸다’를 슬로건으로 진행되어 단체생활을 통해 협동심과 ...</td>\n",
              "      <td>[0, 2, 4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>이데일리</td>\n",
              "      <td>335868123</td>\n",
              "      <td>[서울시는 신학기가 시작되는 다음달 4일부터 고등학교 3학년 무상급식을 실시한다고 ...</td>\n",
              "      <td>서울시가 다음달 4일부터 서울 시내 319개 고등학교 3학년 8만4700명을 대상으...</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>서울신문</td>\n",
              "      <td>351443347</td>\n",
              "      <td>[미국인 선교사가 우간다에서 의사 행세를 하며 의료 시설을 운영한 혐의로 지역 시민...</td>\n",
              "      <td>미국인 선교사가 우간다에서 의사 행세를 하며 두 아이의 죽음과 관련돼 있다며 지역 ...</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  media  ...   extractive\n",
              "0  부산일보  ...  [4, 11, 18]\n",
              "1  중도일보  ...    [1, 3, 4]\n",
              "2  무등일보  ...    [0, 2, 4]\n",
              "3  이데일리  ...    [0, 1, 2]\n",
              "4  서울신문  ...    [0, 1, 2]\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfH6G8X6BGgX",
        "outputId": "428d0acf-f563-47ce-fa5d-6e0c06366dc5"
      },
      "source": [
        "# join으로 str로 바꿔줘야할듯\n",
        "for i,info in enumerate(train_df['article_original'][1]):\n",
        "  print('line {} : {}'.format(i,info))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "line 0 : 서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 우수의정대상을 받았다.\n",
            "line 1 : 가충순 의원과 이수의 의원은 16일 팔봉면 폰타나 리조트에서 열린 한국지역신문협회 하계 워크샵에서 지역사회 발전을 위해 활발한 의정활동을 펼친 공로를 인정받아 우수의정대상을 수상했다.\n",
            "line 2 : 지난해 6월 제7회 전국동시지방선거를 통해 등원한 두 의원은 산업건설위원회에서 열정적인 의정활동을 펼치고 있다.\n",
            "line 3 : 가충순 의원은 5분발언, 행정사무감사, 시정질문을 통해 자동차 연비테스트 연구시설 유치, 천수만 염해피해 재발 방지, 서산시 대표 농산물 육성 등 지역의 크고 작은 문제를 개선하기 위해 노력하고 있다.\n",
            "line 4 : 이수의 의원은 지난 행정사무감사에서 대산공단 기업 임원을 참고인으로 출석시켜 지역인재채용 및 관내업체·자재 활용을 확대할 것을 제안하며 기존 행정사무감사의 틀을 깨는 등 다양한 의정활동을 펼쳐나가고 있다.\n",
            "line 5 : 가충순 의원은 \"시의원이라면 마땅히 해야할 일을 한 것 뿐인데 상까지 주시니 몸 둘 바를 모르겠다\"며 \"항상 초심을 잊지 않고 지역 발전을 위해 최선을 다하겠다\"고 소감을 밝혔다.\n",
            "line 6 : 이수의 의원은 \"믿고 뽑아주신 주민들을 위해 당연히 해야할 일을 했을 뿐인데 상까지 받게 돼 영광\"이라며 \"시민들이 자부심을 느낄 수 있는 지역사회를 만들어 나가기 위해 앞으로도 최선을 다 하겠다\"고 말했다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XsnesnRBKRm"
      },
      "source": [
        "def articles_to_str(articles_list):\n",
        "  return ' '.join(articles_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bd9jgt3BKTy"
      },
      "source": [
        "train_df['article_to_str']=train_df['article_original'].apply(articles_to_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "AySccE9-BKWC",
        "outputId": "b6fcf58d-9ba7-4a60-ed93-24054af946bc"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>media</th>\n",
              "      <th>id</th>\n",
              "      <th>article_original</th>\n",
              "      <th>abstractive</th>\n",
              "      <th>extractive</th>\n",
              "      <th>article_to_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>부산일보</td>\n",
              "      <td>360972161</td>\n",
              "      <td>[지난해 고령화와 유례가 드문 겨울 한파 등 영향으로 우리나라 사망자 수가 통계 작...</td>\n",
              "      <td>통계청이 발표한 '2018년 사망원인통계'를 보면 지난해 총 사망자 수는 관련 통계...</td>\n",
              "      <td>[4, 11, 18]</td>\n",
              "      <td>지난해 고령화와 유례가 드문 겨울 한파 등 영향으로 우리나라 사망자 수가 통계 작성...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>중도일보</td>\n",
              "      <td>356659913</td>\n",
              "      <td>[서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 ...</td>\n",
              "      <td>서산시 가충순 의원과 이수의 의원이 활발한 의정활동을 펼친 감사의 표시로 한국지역신...</td>\n",
              "      <td>[1, 3, 4]</td>\n",
              "      <td>서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 우...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>무등일보</td>\n",
              "      <td>351718460</td>\n",
              "      <td>[지난 2004년 시작해 조선대 학생들의 대표적인 행사로 자리매김한 ‘조선대 국토대...</td>\n",
              "      <td>‘조선대의 새로운 비상을 꿈꾸다’를 슬로건으로 진행되어 단체생활을 통해 협동심과 ...</td>\n",
              "      <td>[0, 2, 4]</td>\n",
              "      <td>지난 2004년 시작해 조선대 학생들의 대표적인 행사로 자리매김한 ‘조선대 국토대장...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>이데일리</td>\n",
              "      <td>335868123</td>\n",
              "      <td>[서울시는 신학기가 시작되는 다음달 4일부터 고등학교 3학년 무상급식을 실시한다고 ...</td>\n",
              "      <td>서울시가 다음달 4일부터 서울 시내 319개 고등학교 3학년 8만4700명을 대상으...</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>서울시는 신학기가 시작되는 다음달 4일부터 고등학교 3학년 무상급식을 실시한다고 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>서울신문</td>\n",
              "      <td>351443347</td>\n",
              "      <td>[미국인 선교사가 우간다에서 의사 행세를 하며 의료 시설을 운영한 혐의로 지역 시민...</td>\n",
              "      <td>미국인 선교사가 우간다에서 의사 행세를 하며 두 아이의 죽음과 관련돼 있다며 지역 ...</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>미국인 선교사가 우간다에서 의사 행세를 하며 의료 시설을 운영한 혐의로 지역 시민단...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  media  ...                                     article_to_str\n",
              "0  부산일보  ...  지난해 고령화와 유례가 드문 겨울 한파 등 영향으로 우리나라 사망자 수가 통계 작성...\n",
              "1  중도일보  ...  서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 우...\n",
              "2  무등일보  ...  지난 2004년 시작해 조선대 학생들의 대표적인 행사로 자리매김한 ‘조선대 국토대장...\n",
              "3  이데일리  ...  서울시는 신학기가 시작되는 다음달 4일부터 고등학교 3학년 무상급식을 실시한다고 2...\n",
              "4  서울신문  ...  미국인 선교사가 우간다에서 의사 행세를 하며 의료 시설을 운영한 혐의로 지역 시민단...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb7JHizMBKaM",
        "outputId": "a688caeb-5471-424a-e3ff-d3bc9730cf8f"
      },
      "source": [
        "print('Length of original dataset:', len(train_df))\n",
        "train_small = train_df[:1000]\n",
        "print('Length of truncated dataset:', len(train_small))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of original dataset: 260697\n",
            "Length of truncated dataset: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbApLY8d8FpR"
      },
      "source": [
        "# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.source_len = source_len\n",
        "        self.summ_len = summ_len\n",
        "        self.text = self.data.text\n",
        "        self.ctext = self.data.ctext\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ctext = str(self.ctext[index])\n",
        "        ctext = ' '.join(ctext.split())\n",
        "\n",
        "        text = str(self.text[index])\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n",
        "        target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n",
        "\n",
        "        source_ids = source['input_ids'].squeeze()\n",
        "        source_mask = source['attention_mask'].squeeze()\n",
        "        target_ids = target['input_ids'].squeeze()\n",
        "        target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'source_ids': source_ids.to(dtype=torch.long), \n",
        "            'source_mask': source_mask.to(dtype=torch.long), \n",
        "            'target_ids': target_ids.to(dtype=torch.long),\n",
        "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "        }\n",
        "\n",
        "1. t5 모델 base로 했는데도 큼"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIhz2goi8Frh"
      },
      "source": [
        "# Creating the training function. This will be called in the main function. It is run depending on the epoch value.\n",
        "# The model is put into train mode and then we wnumerate over the training loader and passed to the defined network \n",
        "\n",
        "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
        "    model.train()\n",
        "    for _,data in enumerate(loader, 0):\n",
        "        y = data['target_ids'].to(device, dtype = torch.long)\n",
        "        y_ids = y[:, :-1].contiguous()\n",
        "        labels = y[:, 1:].clone().detach()\n",
        "        labels[labels[:, :] == tokenizer.pad_token_id] = -100\n",
        "        \n",
        "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        if _%10 == 0:\n",
        "            wandb.log({\"Training Loss\": loss.item()})\n",
        "\n",
        "        if _%500==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # xm.optimizer_step(optimizer)\n",
        "        # xm.mark_step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IimAbPyf8Ftq"
      },
      "source": [
        "def validate(epoch, tokenizer, model, device, loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader, 0):\n",
        "            y = data['target_ids'].to(device, dtype = torch.long)\n",
        "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "            generated_ids = model.generate(\n",
        "                input_ids = ids,\n",
        "                attention_mask = mask, \n",
        "                max_length=150, \n",
        "                num_beams=2,\n",
        "                repetition_penalty=2.5, \n",
        "                length_penalty=1.0, \n",
        "                early_stopping=True\n",
        "                )\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "            if _%100==0:\n",
        "                print(f'Completed {_}')\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(target)\n",
        "    return predictions, actuals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "t6y-K8of-W9g",
        "outputId": "e4bd9ee8-7161-4867-f5fc-5edc450aed47"
      },
      "source": [
        "train_small.rename(columns = {'abstractive' : 'ctext',\n",
        "                              'article_to_str' : 'text'}, inplace = True)\n",
        "train_small.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>media</th>\n",
              "      <th>id</th>\n",
              "      <th>article_original</th>\n",
              "      <th>ctext</th>\n",
              "      <th>extractive</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>부산일보</td>\n",
              "      <td>360972161</td>\n",
              "      <td>[지난해 고령화와 유례가 드문 겨울 한파 등 영향으로 우리나라 사망자 수가 통계 작...</td>\n",
              "      <td>통계청이 발표한 '2018년 사망원인통계'를 보면 지난해 총 사망자 수는 관련 통계...</td>\n",
              "      <td>[4, 11, 18]</td>\n",
              "      <td>지난해 고령화와 유례가 드문 겨울 한파 등 영향으로 우리나라 사망자 수가 통계 작성...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>중도일보</td>\n",
              "      <td>356659913</td>\n",
              "      <td>[서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 ...</td>\n",
              "      <td>서산시 가충순 의원과 이수의 의원이 활발한 의정활동을 펼친 감사의 표시로 한국지역신...</td>\n",
              "      <td>[1, 3, 4]</td>\n",
              "      <td>서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 우...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>무등일보</td>\n",
              "      <td>351718460</td>\n",
              "      <td>[지난 2004년 시작해 조선대 학생들의 대표적인 행사로 자리매김한 ‘조선대 국토대...</td>\n",
              "      <td>‘조선대의 새로운 비상을 꿈꾸다’를 슬로건으로 진행되어 단체생활을 통해 협동심과 ...</td>\n",
              "      <td>[0, 2, 4]</td>\n",
              "      <td>지난 2004년 시작해 조선대 학생들의 대표적인 행사로 자리매김한 ‘조선대 국토대장...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>이데일리</td>\n",
              "      <td>335868123</td>\n",
              "      <td>[서울시는 신학기가 시작되는 다음달 4일부터 고등학교 3학년 무상급식을 실시한다고 ...</td>\n",
              "      <td>서울시가 다음달 4일부터 서울 시내 319개 고등학교 3학년 8만4700명을 대상으...</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>서울시는 신학기가 시작되는 다음달 4일부터 고등학교 3학년 무상급식을 실시한다고 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>서울신문</td>\n",
              "      <td>351443347</td>\n",
              "      <td>[미국인 선교사가 우간다에서 의사 행세를 하며 의료 시설을 운영한 혐의로 지역 시민...</td>\n",
              "      <td>미국인 선교사가 우간다에서 의사 행세를 하며 두 아이의 죽음과 관련돼 있다며 지역 ...</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>미국인 선교사가 우간다에서 의사 행세를 하며 의료 시설을 운영한 혐의로 지역 시민단...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  media  ...                                               text\n",
              "0  부산일보  ...  지난해 고령화와 유례가 드문 겨울 한파 등 영향으로 우리나라 사망자 수가 통계 작성...\n",
              "1  중도일보  ...  서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 우...\n",
              "2  무등일보  ...  지난 2004년 시작해 조선대 학생들의 대표적인 행사로 자리매김한 ‘조선대 국토대장...\n",
              "3  이데일리  ...  서울시는 신학기가 시작되는 다음달 4일부터 고등학교 3학년 무상급식을 실시한다고 2...\n",
              "4  서울신문  ...  미국인 선교사가 우간다에서 의사 행세를 하며 의료 시설을 운영한 혐의로 지역 시민단...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ExxTl098Fvy"
      },
      "source": [
        "def main():\n",
        "    # WandB – Initialize a new run\n",
        "    wandb.init(project=\"kubig_t5_summarization\")\n",
        "\n",
        "    # WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "    # Defining some key variables that will be used later on in the training  \n",
        "    config = wandb.config          # Initialize config\n",
        "    config.TRAIN_BATCH_SIZE = 2    # input batch size for training (default: 64)\n",
        "    config.VALID_BATCH_SIZE = 2    # input batch size for testing (default: 1000)\n",
        "    config.TRAIN_EPOCHS = 5        # number of epochs to train (default: 10)\n",
        "    config.VAL_EPOCHS = 2 \n",
        "    config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
        "    config.SEED = 42               # random seed (default: 42)\n",
        "    config.MAX_LEN = 512\n",
        "    config.SUMMARY_LEN = 150 \n",
        "\n",
        "    # Set random seeds and deterministic pytorch for reproducibility\n",
        "    torch.manual_seed(config.SEED) # pytorch random seed\n",
        "    np.random.seed(config.SEED) # numpy random seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    model_name = 'KETI-AIR/ke-t5-base'\n",
        "    # tokenzier for encoding the text\n",
        "    # tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Importing and Pre-Processing the domain data\n",
        "    # Selecting the needed columns only. \n",
        "    # Adding the summarzie text in front of the text. This is to format the dataset similar to how T5 model was trained for summarization task. \n",
        "    df = train_small[['ctext','text']]\n",
        "    df.ctext = 'summarize: ' + df.ctext\n",
        "    print(df.head())\n",
        "\n",
        "    \n",
        "    # Creation of Dataset and Dataloader\n",
        "    # Defining the train size. So 80% of the data will be used for training and the rest will be used for validation. \n",
        "    train_size = 0.8\n",
        "    train_dataset=df.sample(frac=train_size,random_state = config.SEED)\n",
        "    val_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "    train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "    print(\"FULL Dataset: {}\".format(df.shape))\n",
        "    print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "    print(\"TEST Dataset: {}\".format(val_dataset.shape))\n",
        "\n",
        "\n",
        "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
        "    training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "    val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
        "\n",
        "    # Defining the parameters for creation of dataloaders\n",
        "    train_params = {\n",
        "        'batch_size': config.TRAIN_BATCH_SIZE,\n",
        "        'shuffle': True,\n",
        "        'num_workers': 0\n",
        "        }\n",
        "\n",
        "    val_params = {\n",
        "        'batch_size': config.VALID_BATCH_SIZE,\n",
        "        'shuffle': False,\n",
        "        'num_workers': 0\n",
        "        }\n",
        "\n",
        "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "    training_loader = DataLoader(training_set, **train_params)\n",
        "    val_loader = DataLoader(val_set, **val_params)\n",
        "\n",
        "\n",
        "    \n",
        "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
        "    # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
        "    optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "    # Log metrics with wandb\n",
        "    wandb.watch(model, log=\"all\")\n",
        "    # Training loop\n",
        "    print('Initiating Fine-Tuning for the model on our dataset:')\n",
        "\n",
        "    for epoch in range(config.TRAIN_EPOCHS):\n",
        "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
        "\n",
        "\n",
        "    # Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n",
        "    # Saving the dataframe as predictions.csv\n",
        "    print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe:')\n",
        "    for epoch in range(config.VAL_EPOCHS):\n",
        "        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
        "        final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
        "        final_df.to_csv('./t5_predictions_1.csv')\n",
        "        print('Output Files generated for review.')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}